{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T12:03:45.699095Z",
     "start_time": "2020-09-03T12:03:45.678056Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "from farm.data_handler.data_silo import DataSilo\n",
    "from farm.data_handler.processor import NERProcessor\n",
    "from farm.modeling.optimization import initialize_optimizer\n",
    "from farm.infer import Inferencer\n",
    "from farm.modeling.adaptive_model import AdaptiveModel\n",
    "from farm.modeling.language_model import LanguageModel\n",
    "from farm.modeling.prediction_head import TokenClassificationHead\n",
    "from farm.modeling.tokenization import Tokenizer\n",
    "from farm.train import Trainer\n",
    "from farm.utils import set_all_seeds, MLFlowLogger, initialize_device_settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T12:13:53.200474Z",
     "start_time": "2020-09-03T12:13:50.790257Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " __          __  _                            _        \n",
      " \\ \\        / / | |                          | |       \n",
      "  \\ \\  /\\  / /__| | ___ ___  _ __ ___   ___  | |_ ___  \n",
      "   \\ \\/  \\/ / _ \\ |/ __/ _ \\| '_ ` _ \\ / _ \\ | __/ _ \\ \n",
      "    \\  /\\  /  __/ | (_| (_) | | | | | |  __/ | || (_) |\n",
      "     \\/  \\/ \\___|_|\\___\\___/|_| |_| |_|\\___|  \\__\\___/ \n",
      "  ______      _____  __  __  \n",
      " |  ____/\\   |  __ \\|  \\/  |              _.-^-._    .--.\n",
      " | |__ /  \\  | |__) | \\  / |           .-'   _   '-. |__|\n",
      " |  __/ /\\ \\ |  _  /| |\\/| |          /     |_|     \\|  |\n",
      " | | / ____ \\| | \\ \\| |  | |         /               \\  |\n",
      " |_|/_/    \\_\\_|  \\_\\_|  |_|        /|     _____     |\\ |\n",
      "                                     |    |==|==|    |  |\n",
      "|---||---|---|---|---|---|---|---|---|    |--|--|    |  |\n",
      "|---||---|---|---|---|---|---|---|---|    |==|==|    |  |\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09/03/2020 17:43:53 - INFO - farm.utils -   device: cpu n_gpu: 0, distributed training: False, automatic mixed precision training: None\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    ")\n",
    "\n",
    "ml_logger = MLFlowLogger(tracking_uri=\"https://public-mlflow.deepset.ai/\")\n",
    "ml_logger.init_experiment(experiment_name=\"Public_FARM\", run_name=\"Run_ner\")\n",
    "\n",
    "set_all_seeds(seed=42)\n",
    "device, n_gpu = initialize_device_settings(use_cuda=True)\n",
    "n_epochs = 4\n",
    "batch_size = 32\n",
    "evaluate_every = 400\n",
    "lang_model = \"electra-base\"\n",
    "do_lower_case = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T12:16:05.051774Z",
     "start_time": "2020-09-03T12:15:53.552116Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09/03/2020 17:45:53 - INFO - farm.modeling.tokenization -   Loading tokenizer of type 'ElectraTokenizer'\n",
      "09/03/2020 17:46:02 - INFO - filelock -   Lock 5701365432 acquired on /Users/subir/.cache/torch/transformers/ff085885d4c95651587af553adadd34a26de8a663f2cef709635b48b3bed2bbd.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084.lock\n",
      "09/03/2020 17:46:02 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/google/electra-base-discriminator/vocab.txt not found in cache or force_download set to True, downloading to /Users/subir/.cache/torch/transformers/tmpdif7gc0k\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80a6c475950847aca0ff60e879d8a995",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09/03/2020 17:46:05 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/google/electra-base-discriminator/vocab.txt in cache at /Users/subir/.cache/torch/transformers/ff085885d4c95651587af553adadd34a26de8a663f2cef709635b48b3bed2bbd.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "09/03/2020 17:46:05 - INFO - transformers.file_utils -   creating metadata file for /Users/subir/.cache/torch/transformers/ff085885d4c95651587af553adadd34a26de8a663f2cef709635b48b3bed2bbd.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "09/03/2020 17:46:05 - INFO - filelock -   Lock 5701365432 released on /Users/subir/.cache/torch/transformers/ff085885d4c95651587af553adadd34a26de8a663f2cef709635b48b3bed2bbd.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084.lock\n",
      "09/03/2020 17:46:05 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/google/electra-base-discriminator/vocab.txt from cache at /Users/subir/.cache/torch/transformers/ff085885d4c95651587af553adadd34a26de8a663f2cef709635b48b3bed2bbd.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 1.Create a tokenizer\n",
    "tokenizer = Tokenizer.load(\n",
    "    pretrained_model_name_or_path=\"google/electra-base-discriminator\", do_lower_case=do_lower_case\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T12:27:53.674431Z",
     "start_time": "2020-09-03T12:27:18.220985Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09/03/2020 17:57:19 - INFO - farm.data_handler.data_silo -   \n",
      "Loading data into the data silo ... \n",
      "              ______\n",
      "               |o  |   !\n",
      "   __          |:`_|---'-.\n",
      "  |__|______.-/ _ \\-----.|       \n",
      " (o)(o)------'\\ _ /     ( )      \n",
      " \n",
      "09/03/2020 17:57:19 - INFO - farm.data_handler.data_silo -   Loading train set from: data/finetuning_data/chunk/train.txt \n",
      "09/03/2020 17:57:19 - INFO - farm.data_handler.data_silo -   Multiprocessing disabled, using a single worker to convert 8323dictionaries to pytorch datasets.\n",
      "Preprocessing Dataset data/finetuning_data/chunk/train.txt:   0%|          | 0/8323 [00:00<?, ? Dicts/s]09/03/2020 17:57:36 - INFO - farm.data_handler.processor -   *** Show 2 random examples ***\n",
      "09/03/2020 17:57:36 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: 1824-0\n",
      "Clear Text: \n",
      " \ttext: La citada fuente se mostró asimismo escéptica de que general Dynamics pueda cumplir su promesa de asumir la plantilla completa , algo que , a su juicio , no era realista .\n",
      " \tner_label: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Tokenized: \n",
      " \ttokens: ['[UNK]', 'ci', '##tad', '##a', 'fu', '##ente', 'se', '[UNK]', 'as', '##imi', '##smo', '[UNK]', 'de', 'que', 'general', '[UNK]', 'pu', '##eda', 'cum', '##pl', '##ir', 'su', 'prom', '##esa', 'de', 'as', '##umi', '##r', 'la', 'plant', '##illa', 'com', '##ple', '##ta', ',', 'al', '##go', 'que', ',', 'a', 'su', 'ju', '##icio', ',', 'no', 'era', 'real', '##ista', '.']\n",
      " \toffsets: [0, 3, 5, 8, 10, 12, 17, 20, 27, 29, 32, 36, 46, 49, 53, 61, 70, 72, 76, 79, 81, 84, 87, 91, 95, 98, 100, 103, 105, 108, 113, 118, 121, 124, 127, 129, 131, 134, 138, 140, 142, 145, 147, 152, 154, 157, 161, 165, 170]\n",
      " \tstart_of_word: [True, True, False, False, True, False, True, True, True, False, False, True, True, True, True, True, True, False, True, False, False, True, True, False, True, True, False, False, True, True, False, True, False, False, True, True, False, True, True, True, True, True, False, True, True, True, True, False, True]\n",
      "Features: \n",
      " \tinput_ids: [101, 100, 25022, 17713, 2050, 11865, 15781, 7367, 100, 2004, 27605, 25855, 100, 2139, 10861, 2236, 100, 16405, 11960, 13988, 24759, 4313, 10514, 20877, 22447, 2139, 2004, 12717, 2099, 2474, 3269, 9386, 4012, 10814, 2696, 1010, 2632, 3995, 10861, 1010, 1037, 10514, 18414, 27113, 1010, 2053, 3690, 2613, 11921, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tinitial_mask: [0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tner_label_ids: [1, 2, 2, 1, 1, 2, 1, 2, 2, 2, 1, 1, 2, 2, 2, 7, 8, 2, 1, 2, 1, 1, 2, 2, 1, 2, 2, 1, 1, 2, 2, 1, 2, 1, 1, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "_____________________________________________________\n",
      "09/03/2020 17:57:36 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: 4506-0\n",
      "Clear Text: \n",
      " \ttext: \" El Vasconia fue un club de fútbol con una sección de baloncesto , que creció mucho y se hizo autónoma como Baskonia \" , recordó .\n",
      " \tner_label: ['O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O']\n",
      "Tokenized: \n",
      " \ttokens: ['\"', '[UNK]', '[UNK]', 'fu', '##e', 'un', 'club', 'de', '[UNK]', 'con', 'una', '[UNK]', 'de', 'bal', '##on', '##ces', '##to', ',', 'que', '[UNK]', 'much', '##o', 'y', 'se', 'hi', '##zo', '[UNK]', 'como', '[UNK]', '\"', ',', '[UNK]', '.']\n",
      " \toffsets: [0, 2, 5, 14, 16, 18, 21, 26, 29, 36, 40, 44, 52, 55, 58, 60, 63, 66, 68, 72, 79, 83, 85, 87, 90, 92, 95, 104, 109, 118, 120, 122, 130]\n",
      " \tstart_of_word: [True, True, True, True, False, True, True, True, True, True, True, True, True, True, False, False, False, True, True, True, True, False, True, True, True, False, True, True, True, True, True, True, True]\n",
      "Features: \n",
      " \tinput_ids: [101, 1000, 100, 100, 11865, 2063, 4895, 2252, 2139, 100, 9530, 14477, 100, 2139, 28352, 2239, 9623, 3406, 1010, 10861, 100, 2172, 2080, 1061, 7367, 7632, 6844, 100, 18609, 100, 1000, 1010, 100, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tinitial_mask: [0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tner_label_ids: [1, 2, 2, 7, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 7, 2, 2, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "_____________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing Dataset data/finetuning_data/chunk/train.txt:  20%|██        | 1665/8323 [00:16<01:07, 98.50 Dicts/s]\n",
      "09/03/2020 17:57:36 - INFO - farm.data_handler.data_silo -   Loading dev set from: data/finetuning_data/chunk/dev.txt\n",
      "09/03/2020 17:57:36 - INFO - farm.data_handler.data_silo -   Multiprocessing disabled, using a single worker to convert 1915dictionaries to pytorch datasets.\n",
      "Preprocessing Dataset data/finetuning_data/chunk/dev.txt:   0%|          | 0/1915 [00:00<?, ? Dicts/s]09/03/2020 17:57:39 - INFO - farm.data_handler.processor -   *** Show 2 random examples ***\n",
      "09/03/2020 17:57:39 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: 457-0\n",
      "Clear Text: \n",
      " \ttext: López de Arriortúa sí tuvo relación como asesor de un grupo de inversores que presentó una serie de propuestas que en septiembre de 1999 fueron rechazadas en la reunión anual de la Junta de Accionistas de Leica .\n",
      " \tner_label: ['B-PER', 'I-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O']\n",
      "Tokenized: \n",
      " \ttokens: ['[UNK]', 'de', '[UNK]', '[UNK]', 'tu', '##vo', '[UNK]', 'como', 'as', '##es', '##or', 'de', 'un', 'grupo', 'de', 'in', '##vers', '##ores', 'que', '[UNK]', 'una', 'serie', 'de', 'prop', '##ues', '##tas', 'que', 'en', 'sept', '##ie', '##mbre', 'de', '1999', 'fu', '##eron', 'rec', '##ha', '##za', '##das', 'en', 'la', '[UNK]', 'an', '##ual', 'de', 'la', '[UNK]', 'de', '[UNK]', 'de', '[UNK]', '.']\n",
      " \toffsets: [0, 6, 9, 19, 22, 24, 27, 36, 41, 43, 45, 48, 51, 54, 60, 63, 65, 69, 74, 78, 87, 91, 97, 100, 104, 107, 111, 115, 118, 122, 124, 129, 132, 137, 139, 144, 147, 149, 151, 155, 158, 161, 169, 171, 175, 178, 181, 187, 190, 202, 205, 211]\n",
      " \tstart_of_word: [True, True, True, True, True, False, True, True, True, False, False, True, True, True, True, True, False, False, True, True, True, True, True, True, False, False, True, True, True, False, False, True, True, True, False, True, False, False, False, True, True, True, True, False, True, True, True, True, True, True, True, True]\n",
      "Features: \n",
      " \tinput_ids: [101, 100, 2139, 100, 100, 10722, 6767, 100, 18609, 2004, 2229, 2953, 2139, 4895, 26678, 2139, 1999, 14028, 16610, 10861, 100, 14477, 8668, 2139, 17678, 15808, 10230, 10861, 4372, 17419, 2666, 19908, 2139, 2639, 11865, 26534, 28667, 3270, 4143, 8883, 4372, 2474, 100, 2019, 8787, 2139, 2474, 100, 2139, 100, 2139, 100, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tinitial_mask: [0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tner_label_ids: [1, 5, 6, 6, 2, 2, 1, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 1, 1, 2, 2, 2, 1, 2, 1, 1, 1, 2, 2, 2, 2, 1, 2, 2, 7, 8, 8, 8, 8, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "_____________________________________________________\n",
      "09/03/2020 17:57:39 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: 1508-0\n",
      "Clear Text: \n",
      " \ttext: ( SV2147 ) PP : PROBLEMAS INTERNOS PSOE INTERFIEREN EN POLITICA DE LA JUNTA Córdoba ( EFE ) .\n",
      " \tner_label: ['O', 'B-MISC', 'O', 'B-ORG', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'B-ORG', 'O', 'O']\n",
      "Tokenized: \n",
      " \ttokens: ['(', '[UNK]', ')', '[UNK]', ':', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '(', '[UNK]', ')', '.']\n",
      " \toffsets: [0, 2, 9, 11, 14, 16, 26, 35, 40, 52, 55, 64, 67, 70, 76, 84, 86, 90, 92]\n",
      " \tstart_of_word: [True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\n",
      "Features: \n",
      " \tinput_ids: [101, 1006, 100, 1007, 100, 1024, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 1006, 100, 1007, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tinitial_mask: [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tner_label_ids: [1, 2, 3, 2, 7, 2, 2, 2, 7, 2, 2, 2, 2, 2, 2, 9, 2, 7, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "_____________________________________________________\n",
      "Preprocessing Dataset data/finetuning_data/chunk/dev.txt:  20%|██        | 383/1915 [00:02<00:11, 132.09 Dicts/s]\n",
      "09/03/2020 17:57:39 - INFO - farm.data_handler.data_silo -   Loading test set from: data/finetuning_data/chunk/test.txt\n",
      "09/03/2020 17:57:39 - INFO - farm.data_handler.data_silo -   Multiprocessing disabled, using a single worker to convert 1517dictionaries to pytorch datasets.\n",
      "Preprocessing Dataset data/finetuning_data/chunk/test.txt:   0%|          | 0/1517 [00:00<?, ? Dicts/s]09/03/2020 17:57:42 - INFO - farm.data_handler.processor -   *** Show 2 random examples ***\n",
      "09/03/2020 17:57:42 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: 1385-0\n",
      "Clear Text: \n",
      " \ttext: Tras entrevistarse con el secretario del Tesoro de EEUU , Lawrence Summers , Rato dijo que la mejor forma de favorecer los intereses de los ciudadanos españoles es facilitar que haya mayor competencia y oferta en la venta de la gasolina .\n",
      " \tner_label: ['O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'B-LOC', 'O', 'B-PER', 'I-PER', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Tokenized: \n",
      " \ttokens: ['[UNK]', 'en', '##tre', '##vis', '##tar', '##se', 'con', 'el', 'secret', '##ario', 'del', '[UNK]', 'de', '[UNK]', ',', '[UNK]', '[UNK]', ',', '[UNK]', 'di', '##jo', 'que', 'la', 'me', '##jo', '##r', 'form', '##a', 'de', 'favor', '##ece', '##r', 'los', 'inter', '##eses', 'de', 'los', 'ciudad', '##ano', '##s', '[UNK]', 'es', 'fa', '##ci', '##lita', '##r', 'que', 'hay', '##a', 'mayor', 'compete', '##ncia', 'y', 'of', '##ert', '##a', 'en', 'la', 'vent', '##a', 'de', 'la', 'gas', '##olin', '##a', '.']\n",
      " \toffsets: [0, 5, 7, 10, 13, 16, 19, 23, 26, 32, 37, 41, 48, 51, 56, 58, 67, 75, 77, 82, 84, 87, 91, 94, 96, 98, 100, 104, 106, 109, 114, 117, 119, 123, 128, 133, 136, 140, 146, 149, 151, 161, 164, 166, 168, 172, 174, 178, 181, 183, 189, 196, 201, 203, 205, 208, 210, 213, 216, 220, 222, 225, 228, 231, 235, 237]\n",
      " \tstart_of_word: [True, True, False, False, False, False, True, True, True, False, True, True, True, True, True, True, True, True, True, True, False, True, True, True, False, False, True, False, True, True, False, False, True, True, False, True, True, True, False, False, True, True, True, False, False, False, True, True, False, True, True, False, True, True, False, False, True, True, True, False, True, True, True, False, False, True]\n",
      "Features: \n",
      " \tinput_ids: [101, 100, 4372, 7913, 11365, 7559, 3366, 9530, 3449, 3595, 16843, 3972, 100, 2139, 100, 1010, 100, 100, 1010, 100, 4487, 5558, 10861, 2474, 2033, 5558, 2099, 2433, 2050, 2139, 5684, 26005, 2099, 3050, 6970, 23072, 2139, 3050, 20759, 6761, 2015, 100, 9686, 6904, 6895, 27606, 2099, 10861, 10974, 2050, 3664, 5566, 22750, 1061, 1997, 8743, 2050, 4372, 2474, 18834, 2050, 2139, 2474, 3806, 18861, 2050, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tinitial_mask: [0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tner_label_ids: [1, 2, 2, 1, 1, 1, 1, 2, 2, 2, 1, 2, 3, 2, 9, 2, 5, 6, 2, 5, 2, 1, 2, 2, 2, 1, 1, 2, 1, 2, 2, 1, 1, 2, 2, 1, 2, 2, 2, 1, 1, 2, 2, 2, 1, 1, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 1, 2, 2, 2, 1, 2, 2, 2, 1, 1, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "_____________________________________________________\n",
      "09/03/2020 17:57:42 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: 1209-0\n",
      "Clear Text: \n",
      " \ttext: La directora del departamento de Márketing de la firma Space Adventures , del estado norteamericano de Virginia , Sarah Dalton , tras subrayar esta posibilidad , manifestó que su empresa ya ofrece viajes \" de gravedad cero \" , actualmente \" accesibles a unos pocos \" por sus altos precios , pero que \" serán extensibles a la sociedad dentro de pocas décadas cuando , claro está , se economicen los gastos \" .\n",
      " \tner_label: ['O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Tokenized: \n",
      " \ttokens: ['[UNK]', 'director', '##a', 'del', 'depart', '##ament', '##o', 'de', '[UNK]', 'de', 'la', 'firm', '##a', '[UNK]', '[UNK]', ',', 'del', 'est', '##ado', 'norte', '##ame', '##rica', '##no', 'de', '[UNK]', ',', '[UNK]', '[UNK]', ',', 'tr', '##as', 'sub', '##raya', '##r', 'est', '##a', 'po', '##si', '##bil', '##idad', ',', '[UNK]', 'que', 'su', 'em', '##pres', '##a', 'ya', 'of', '##re', '##ce', 'via', '##je', '##s', '\"', 'de', 'grave', '##dad', 'ce', '##ro', '\"', ',', 'actual', '##ment', '##e', '\"', 'acc', '##es', '##ible', '##s', 'a', 'uno', '##s', 'po', '##cos', '\"', 'por', 'su', '##s', 'alto', '##s', 'pre', '##cio', '##s', ',', 'per', '##o', 'que', '\"', '[UNK]', 'ex', '##tens', '##ible', '##s', 'a', 'la', 'soc', '##ied', '##ad', 'dent', '##ro', 'de', 'po', '##cas', '[UNK]', 'cu', '##ando', ',', 'cl', '##aro', '[UNK]', ',', 'se', 'economic', '##en', 'los', 'gas', '##tos', '\"', '.']\n",
      " \toffsets: [0, 3, 11, 13, 17, 23, 28, 30, 33, 43, 46, 49, 53, 55, 61, 72, 74, 78, 81, 85, 90, 93, 97, 100, 103, 112, 114, 120, 127, 129, 131, 134, 137, 141, 143, 146, 148, 150, 152, 155, 160, 162, 172, 176, 179, 181, 185, 187, 190, 192, 194, 197, 200, 202, 204, 206, 209, 214, 218, 220, 223, 225, 227, 233, 237, 239, 241, 244, 246, 250, 252, 254, 257, 259, 261, 265, 267, 271, 273, 275, 279, 281, 284, 287, 289, 291, 294, 296, 300, 302, 308, 310, 314, 318, 320, 322, 325, 328, 331, 334, 338, 341, 344, 346, 350, 358, 360, 365, 367, 369, 373, 378, 380, 383, 391, 394, 398, 401, 405, 407]\n",
      " \tstart_of_word: [True, True, False, True, True, False, False, True, True, True, True, True, False, True, True, True, True, True, False, True, False, False, False, True, True, True, True, True, True, True, False, True, False, False, True, False, True, False, False, False, True, True, True, True, True, False, False, True, True, False, False, True, False, False, True, True, True, False, True, False, True, True, True, False, False, True, True, False, False, False, True, True, False, True, False, True, True, True, False, True, False, True, False, False, True, True, False, True, True, True, True, False, False, False, True, True, True, False, False, True, False, True, True, False, True, True, False, True, True, False, True, True, True, True, False, True, True, False, True, True]\n",
      "Features: \n",
      " \tinput_ids: [101, 100, 2472, 2050, 3972, 18280, 24996, 2080, 2139, 100, 2139, 2474, 3813, 2050, 100, 100, 1010, 3972, 9765, 9365, 19931, 14074, 14735, 3630, 2139, 100, 1010, 100, 100, 1010, 19817, 3022, 4942, 29539, 2099, 9765, 2050, 13433, 5332, 14454, 27893, 1010, 100, 10861, 10514, 7861, 28994, 2050, 8038, 1997, 2890, 3401, 3081, 6460, 2015, 1000, 2139, 6542, 14697, 8292, 3217, 1000, 1010, 5025, 3672, 2063, 1000, 16222, 2229, 7028, 2015, 1037, 27776, 2015, 13433, 13186, 1000, 18499, 10514, 2015, 10766, 2015, 3653, 9793, 2015, 1010, 2566, 2080, 10861, 1000, 100, 4654, 25808, 7028, 2015, 1037, 2474, 27084, 6340, 4215, 21418, 3217, 2139, 13433, 15671, 100, 12731, 28574, 1010, 18856, 10464, 100, 1010, 7367, 3171, 2368, 3050, 3806, 13122, 1000, 1012, 102, 0, 0, 0, 0, 0, 0]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tinitial_mask: [0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tner_label_ids: [1, 2, 2, 1, 2, 2, 1, 1, 2, 3, 2, 2, 2, 1, 7, 8, 2, 2, 2, 1, 2, 1, 1, 1, 2, 9, 2, 5, 6, 2, 2, 1, 2, 1, 1, 2, 1, 2, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 2, 2, 1, 1, 2, 1, 1, 2, 2, 2, 1, 2, 1, 2, 2, 2, 1, 1, 2, 2, 1, 1, 1, 2, 2, 1, 2, 1, 2, 2, 2, 1, 2, 1, 2, 1, 1, 2, 2, 1, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 1, 1, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 1, 0, 0, 0, 0, 0, 0]\n",
      "_____________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing Dataset data/finetuning_data/chunk/test.txt:  20%|██        | 304/1517 [00:02<00:11, 101.34 Dicts/s]\n",
      "09/03/2020 17:57:42 - INFO - farm.data_handler.data_silo -   Examples in train: 8323\n",
      "09/03/2020 17:57:42 - INFO - farm.data_handler.data_silo -   Examples in dev  : 1915\n",
      "09/03/2020 17:57:42 - INFO - farm.data_handler.data_silo -   Examples in test : 1517\n",
      "09/03/2020 17:57:42 - INFO - farm.data_handler.data_silo -   \n",
      "09/03/2020 17:57:42 - INFO - farm.data_handler.data_silo -   Longest sequence length observed after clipping:     128\n",
      "09/03/2020 17:57:42 - INFO - farm.data_handler.data_silo -   Average sequence length after clipping: 48.31575153189956\n",
      "09/03/2020 17:57:42 - INFO - farm.data_handler.data_silo -   Proportion clipped:      0.005046257359125316\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Can't load config for 'electra-base'. Make sure that:\n\n- 'electra-base' is a correct model identifier listed on 'https://huggingface.co/models'\n\n- or 'electra-base' is the correct path to a directory containing a config.json file\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m~/.local/share/virtualenvs/Electra-PszQOton/lib/python3.7/site-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mget_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresolved_config_file\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mEnvironmentError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m             \u001b[0mconfig_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dict_from_json_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolved_config_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-dcc0d193d397>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# 4. Create an AdaptiveModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# a) which consists of a pretrained language model as a basis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mlanguage_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLanguageModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;31m# b) and a prediction head on top that is suited for our task => NER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprediction_head\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTokenClassificationHead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mner_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/Electra-PszQOton/lib/python3.7/site-packages/farm/modeling/language_model.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, pretrained_model_name_or_path, n_added_tokens, language_model_class, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlanguage_model_class\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m                 \u001b[0mlanguage_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlanguage_model_class\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m                 \u001b[0mlanguage_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/Electra-PszQOton/lib/python3.7/site-packages/farm/modeling/language_model.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, pretrained_model_name_or_path, language, **kwargs)\u001b[0m\n\u001b[1;32m   1244\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1245\u001b[0m             \u001b[0;31m# Transformers Style\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1246\u001b[0;31m             \u001b[0melectra\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mElectraModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1247\u001b[0m             \u001b[0melectra\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlanguage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_or_infer_language_from_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melectra\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/Electra-PszQOton/lib/python3.7/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    602\u001b[0m                 \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m                 \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_files_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 604\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    605\u001b[0m             )\n\u001b[1;32m    606\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/Electra-PszQOton/lib/python3.7/site-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \"\"\"\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/Electra-PszQOton/lib/python3.7/site-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mget_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    249\u001b[0m                 \u001b[0;34mf\"- or '{pretrained_model_name_or_path}' is the correct path to a directory containing a {CONFIG_NAME} file\\n\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m             )\n\u001b[0;32m--> 251\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mEnvironmentError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Can't load config for 'electra-base'. Make sure that:\n\n- 'electra-base' is a correct model identifier listed on 'https://huggingface.co/models'\n\n- or 'electra-base' is the correct path to a directory containing a config.json file\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2. Create a DataProcessor that handles all the conversion from raw text into a pytorch Dataset\n",
    "# See test/sample/ner/train-sample.txt for an example of the data format that is expected by the Processor\n",
    "ner_labels = [\"[PAD]\", \"X\", \"O\", \"B-MISC\", \"I-MISC\", \"B-PER\", \"I-PER\", \"B-ORG\", \"I-ORG\", \"B-LOC\", \"I-LOC\", \"B-OTH\", \"I-OTH\"]\n",
    "\n",
    "processor = NERProcessor(\n",
    "    tokenizer=tokenizer, max_seq_len=128, data_dir=Path(\"data//finetuning_data//chunk\"), delimiter=\" \", metric=\"seq_f1\", label_list=ner_labels\n",
    ")\n",
    "\n",
    "# 3. Create a DataSilo that loads several datasets (train/dev/test), provides DataLoaders for them and calculates a few descriptive statistics of our datasets\n",
    "data_silo = DataSilo(processor=processor, batch_size=batch_size, max_processes=1, distributed=False)\n",
    "\n",
    "# 4. Create an AdaptiveModel\n",
    "# a) which consists of a pretrained language model as a basis\n",
    "language_model = LanguageModel.load(lang_model)\n",
    "# b) and a prediction head on top that is suited for our task => NER\n",
    "prediction_head = TokenClassificationHead(num_labels=len(ner_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T12:10:23.333719Z",
     "start_time": "2020-09-03T12:05:15.935427Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " __          __  _                            _        \n",
      " \\ \\        / / | |                          | |       \n",
      "  \\ \\  /\\  / /__| | ___ ___  _ __ ___   ___  | |_ ___  \n",
      "   \\ \\/  \\/ / _ \\ |/ __/ _ \\| '_ ` _ \\ / _ \\ | __/ _ \\ \n",
      "    \\  /\\  /  __/ | (_| (_) | | | | | |  __/ | || (_) |\n",
      "     \\/  \\/ \\___|_|\\___\\___/|_| |_| |_|\\___|  \\__\\___/ \n",
      "  ______      _____  __  __  \n",
      " |  ____/\\   |  __ \\|  \\/  |              _.-^-._    .--.\n",
      " | |__ /  \\  | |__) | \\  / |           .-'   _   '-. |__|\n",
      " |  __/ /\\ \\ |  _  /| |\\/| |          /     |_|     \\|  |\n",
      " | | / ____ \\| | \\ \\| |  | |         /               \\  |\n",
      " |_|/_/    \\_\\_|  \\_\\_|  |_|        /|     _____     |\\ |\n",
      "                                     |    |==|==|    |  |\n",
      "|---||---|---|---|---|---|---|---|---|    |--|--|    |  |\n",
      "|---||---|---|---|---|---|---|---|---|    |==|==|    |  |\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09/03/2020 17:35:18 - INFO - farm.utils -   device: cpu n_gpu: 0, distributed training: False, automatic mixed precision training: None\n",
      "09/03/2020 17:35:18 - INFO - farm.modeling.tokenization -   Loading tokenizer of type 'BertTokenizer'\n",
      "09/03/2020 17:35:19 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /Users/subir/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "09/03/2020 17:35:20 - INFO - farm.data_handler.data_silo -   \n",
      "Loading data into the data silo ... \n",
      "              ______\n",
      "               |o  |   !\n",
      "   __          |:`_|---'-.\n",
      "  |__|______.-/ _ \\-----.|       \n",
      " (o)(o)------'\\ _ /     ( )      \n",
      " \n",
      "09/03/2020 17:35:20 - INFO - farm.data_handler.data_silo -   Loading train set from: data/finetuning_data/chunk/train.txt \n",
      "09/03/2020 17:35:21 - INFO - farm.data_handler.data_silo -   Got ya 3 parallel workers to convert 8323 dictionaries to pytorch datasets (chunksize = 555)...\n",
      "09/03/2020 17:35:21 - INFO - farm.data_handler.data_silo -    0    0    0 \n",
      "09/03/2020 17:35:21 - INFO - farm.data_handler.data_silo -   /w\\  /w\\  /w\\\n",
      "09/03/2020 17:35:21 - INFO - farm.data_handler.data_silo -   /'\\  / \\  /'\\\n",
      "09/03/2020 17:35:21 - INFO - farm.data_handler.data_silo -       \n",
      "Preprocessing Dataset data/finetuning_data/chunk/train.txt:   0%|          | 0/8323 [00:00<?, ? Dicts/s]09/03/2020 17:35:22 - INFO - farm.data_handler.processor -   *** Show 2 random examples ***\n",
      "09/03/2020 17:35:22 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: 384-0\n",
      "Clear Text: \n",
      " \ttext: Siria considera que la retirada israelí del sur del Líbano , completada el miércoles , \" indica que Israel fue derrotado política y militarmente \" , informa hoy la prensa oficial siria .\n",
      " \tner_label: ['B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Tokenized: \n",
      " \ttokens: ['[UNK]', 'consider', '##a', 'que', 'la', 're', '##ti', '##rada', '[UNK]', 'del', 'sur', 'del', '[UNK]', ',', 'com', '##ple', '##tad', '##a', 'el', '[UNK]', ',', '\"', 'ind', '##ica', 'que', '[UNK]', 'fu', '##e', 'der', '##rot', '##ado', '[UNK]', 'y', 'mil', '##ita', '##rm', '##ente', '\"', ',', 'inform', '##a', 'ho', '##y', 'la', 'pre', '##ns', '##a', 'of', '##icia', '##l', 'sir', '##ia', '.']\n",
      " \toffsets: [0, 6, 14, 16, 20, 23, 25, 27, 32, 40, 44, 48, 52, 59, 61, 64, 67, 70, 72, 75, 85, 87, 89, 92, 96, 100, 107, 109, 111, 114, 117, 121, 130, 132, 135, 138, 140, 145, 147, 149, 155, 157, 159, 161, 164, 167, 169, 171, 173, 177, 179, 182, 185]\n",
      " \tstart_of_word: [True, True, False, True, True, True, False, False, True, True, True, True, True, True, True, False, False, False, True, True, True, True, True, False, True, True, True, False, True, False, False, True, True, True, False, False, False, True, True, True, False, True, False, True, True, False, False, True, False, False, True, False, True]\n",
      "Features: \n",
      " \tinput_ids: [101, 100, 5136, 2050, 10861, 2474, 2128, 3775, 28510, 100, 3972, 7505, 3972, 100, 1010, 4012, 10814, 17713, 2050, 3449, 100, 1010, 1000, 27427, 5555, 10861, 100, 11865, 2063, 4315, 21709, 9365, 100, 1061, 23689, 6590, 10867, 15781, 1000, 1010, 12367, 2050, 7570, 2100, 2474, 3653, 3619, 2050, 1997, 24108, 2140, 2909, 2401, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tinitial_mask: [0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tner_label_ids: [1, 7, 2, 1, 2, 2, 2, 1, 1, 2, 2, 2, 2, 9, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 1, 2, 7, 2, 1, 2, 1, 1, 2, 2, 2, 1, 1, 1, 2, 2, 2, 1, 2, 1, 2, 2, 1, 1, 2, 1, 1, 2, 1, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "_____________________________________________________\n",
      "09/03/2020 17:35:22 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: 316-0\n",
      "Clear Text: \n",
      " \ttext: Tokio , 25 may ( EFECOM ) .\n",
      " \tner_label: ['B-LOC', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O']\n",
      "Tokenized: \n",
      " \ttokens: ['[UNK]', ',', '25', 'may', '(', '[UNK]', ')', '.']\n",
      " \toffsets: [0, 6, 8, 11, 15, 17, 24, 26]\n",
      " \tstart_of_word: [True, True, True, True, True, True, True, True]\n",
      "Features: \n",
      " \tinput_ids: [101, 100, 1010, 2423, 2089, 1006, 100, 1007, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tinitial_mask: [0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tner_label_ids: [1, 9, 2, 2, 2, 2, 7, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "_____________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing Dataset data/finetuning_data/chunk/train.txt: 100%|██████████| 8323/8323 [00:08<00:00, 1016.77 Dicts/s]\n",
      "09/03/2020 17:35:29 - INFO - farm.data_handler.data_silo -   Loading dev set from: data/finetuning_data/chunk/dev.txt\n",
      "09/03/2020 17:35:29 - INFO - farm.data_handler.data_silo -   Got ya 3 parallel workers to convert 1915 dictionaries to pytorch datasets (chunksize = 128)...\n",
      "09/03/2020 17:35:29 - INFO - farm.data_handler.data_silo -    0    0    0 \n",
      "09/03/2020 17:35:29 - INFO - farm.data_handler.data_silo -   /w\\  /w\\  /w\\\n",
      "09/03/2020 17:35:29 - INFO - farm.data_handler.data_silo -   /'\\  / \\  / \\\n",
      "09/03/2020 17:35:29 - INFO - farm.data_handler.data_silo -       \n",
      "Preprocessing Dataset data/finetuning_data/chunk/dev.txt:   0%|          | 0/1915 [00:00<?, ? Dicts/s]09/03/2020 17:35:29 - INFO - farm.data_handler.processor -   *** Show 2 random examples ***\n",
      "09/03/2020 17:35:29 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: 32-0\n",
      "Clear Text: \n",
      " \ttext: Estos por su magnífica presentación y extraordinaria condición para ver y hacer el toreo : una verdadera corrida de toros , y con calidad .\n",
      " \tner_label: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Tokenized: \n",
      " \ttokens: ['[UNK]', 'por', 'su', '[UNK]', '[UNK]', 'y', 'extra', '##ord', '##ina', '##ria', '[UNK]', 'para', 've', '##r', 'y', 'ha', '##cer', 'el', 'tore', '##o', ':', 'una', 've', '##rda', '##der', '##a', 'co', '##rri', '##da', 'de', 'toro', '##s', ',', 'y', 'con', 'cal', '##idad', '.']\n",
      " \toffsets: [0, 6, 10, 13, 23, 36, 38, 43, 46, 49, 53, 63, 68, 70, 72, 74, 76, 80, 83, 87, 89, 91, 95, 97, 100, 103, 105, 107, 110, 113, 116, 120, 122, 124, 126, 130, 133, 138]\n",
      " \tstart_of_word: [True, True, True, True, True, True, True, False, False, False, True, True, True, False, True, True, False, True, True, False, True, True, True, False, False, False, True, False, False, True, True, False, True, True, True, True, False, True]\n",
      "Features: \n",
      " \tinput_ids: [101, 100, 18499, 10514, 100, 100, 1061, 4469, 8551, 3981, 4360, 100, 11498, 2310, 2099, 1061, 5292, 17119, 3449, 9538, 2080, 1024, 14477, 2310, 13639, 4063, 2050, 2522, 18752, 2850, 2139, 23790, 2015, 1010, 1061, 9530, 10250, 27893, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tinitial_mask: [0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tner_label_ids: [1, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 2, 1, 1, 1, 2, 1, 1, 2, 2, 1, 2, 2, 2, 2, 1, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "_____________________________________________________\n",
      "09/03/2020 17:35:29 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: 76-0\n",
      "Clear Text: \n",
      " \ttext: -\n",
      " \tner_label: ['O']\n",
      "Tokenized: \n",
      " \ttokens: ['-']\n",
      " \toffsets: [0]\n",
      " \tstart_of_word: [True]\n",
      "Features: \n",
      " \tinput_ids: [101, 1011, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tpadding_mask: [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tinitial_mask: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tner_label_ids: [1, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "_____________________________________________________\n",
      "Preprocessing Dataset data/finetuning_data/chunk/dev.txt: 100%|██████████| 1915/1915 [00:01<00:00, 1007.31 Dicts/s]\n",
      "09/03/2020 17:35:31 - INFO - farm.data_handler.data_silo -   Loading test set from: data/finetuning_data/chunk/test.txt\n",
      "09/03/2020 17:35:31 - INFO - farm.data_handler.data_silo -   Got ya 3 parallel workers to convert 1517 dictionaries to pytorch datasets (chunksize = 102)...\n",
      "09/03/2020 17:35:31 - INFO - farm.data_handler.data_silo -    0    0    0 \n",
      "09/03/2020 17:35:31 - INFO - farm.data_handler.data_silo -   /w\\  /|\\  /w\\\n",
      "09/03/2020 17:35:31 - INFO - farm.data_handler.data_silo -   /'\\  /'\\  /'\\\n",
      "09/03/2020 17:35:31 - INFO - farm.data_handler.data_silo -       \n",
      "Preprocessing Dataset data/finetuning_data/chunk/test.txt:   0%|          | 0/1517 [00:00<?, ? Dicts/s]09/03/2020 17:35:32 - INFO - farm.data_handler.processor -   *** Show 2 random examples ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09/03/2020 17:35:32 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: 38-0\n",
      "Clear Text: \n",
      " \ttext: En toda Castilla-La Mancha la pérdida superaría los 8.000 millones tras haberse incrementado el gasóleo agrícola desde 38 pesetas el litro en enero de 1999 a 66 pesetas en la actualidad .\n",
      " \tner_label: ['O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Tokenized: \n",
      " \ttokens: ['[UNK]', 'tod', '##a', '[UNK]', '-', '[UNK]', '[UNK]', 'la', '[UNK]', '[UNK]', 'los', '8', '.', '000', 'mill', '##ones', 'tr', '##as', 'ha', '##bers', '##e', 'inc', '##rem', '##ent', '##ado', 'el', '[UNK]', '[UNK]', 'des', '##de', '38', 'pe', '##set', '##as', 'el', 'lit', '##ro', 'en', 'en', '##ero', 'de', '1999', 'a', '66', 'pe', '##set', '##as', 'en', 'la', 'actual', '##idad', '.']\n",
      " \toffsets: [0, 3, 6, 8, 13, 14, 20, 27, 30, 38, 48, 52, 53, 54, 58, 62, 67, 69, 72, 74, 78, 80, 83, 86, 89, 93, 96, 104, 113, 116, 119, 122, 124, 127, 130, 133, 136, 139, 142, 144, 148, 151, 156, 158, 161, 163, 166, 169, 172, 175, 181, 186]\n",
      " \tstart_of_word: [True, True, False, True, False, False, True, True, True, True, True, True, False, False, True, False, True, False, True, False, False, True, False, False, False, True, True, True, True, False, True, True, False, False, True, True, False, True, True, False, True, True, True, True, True, False, False, True, True, True, False, True]\n",
      "Features: \n",
      " \tinput_ids: [101, 100, 28681, 2050, 100, 1011, 100, 100, 2474, 100, 100, 3050, 1022, 1012, 2199, 4971, 21821, 19817, 3022, 5292, 17198, 2063, 4297, 28578, 4765, 9365, 3449, 100, 100, 4078, 3207, 4229, 21877, 13462, 3022, 3449, 5507, 3217, 4372, 4372, 10624, 2139, 2639, 1037, 5764, 21877, 13462, 3022, 4372, 2474, 5025, 27893, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tinitial_mask: [0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tner_label_ids: [1, 2, 2, 1, 9, 1, 1, 10, 2, 2, 2, 2, 2, 1, 1, 2, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 2, 2, 2, 2, 1, 2, 2, 1, 1, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 1, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "_____________________________________________________\n",
      "09/03/2020 17:35:32 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: 62-0\n",
      "Clear Text: \n",
      " \ttext: El árbitro , Florentino Feliciano , concedió hoy a Chile un plazo de catorce meses. nueve días. partir del doce de enero de 2000 , la fecha de aprobación de la sentencia por parte de la OMC , para el cambio de legislación .\n",
      " \tner_label: ['O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Tokenized: \n",
      " \ttokens: ['[UNK]', '[UNK]', ',', '[UNK]', '[UNK]', ',', '[UNK]', 'ho', '##y', 'a', '[UNK]', 'un', 'pl', '##az', '##o', 'de', 'cat', '##or', '##ce', 'me', '##ses', '.', 'nu', '##eve', '[UNK]', '.', 'part', '##ir', 'del', 'doc', '##e', 'de', 'en', '##ero', 'de', '2000', ',', 'la', 'fe', '##cha', 'de', '[UNK]', 'de', 'la', 'sent', '##encia', 'por', 'part', '##e', 'de', 'la', '[UNK]', ',', 'para', 'el', 'cam', '##bio', 'de', '[UNK]', '.']\n",
      " \toffsets: [0, 3, 11, 13, 24, 34, 36, 45, 47, 49, 51, 57, 60, 62, 64, 66, 69, 72, 74, 77, 79, 82, 84, 86, 90, 95, 96, 100, 103, 107, 110, 112, 115, 117, 121, 124, 129, 131, 134, 136, 140, 143, 154, 157, 160, 164, 170, 174, 178, 180, 183, 186, 190, 192, 197, 200, 203, 207, 210, 222]\n",
      " \tstart_of_word: [True, True, True, True, True, True, True, True, False, True, True, True, True, False, False, True, True, False, False, True, False, False, True, False, True, False, True, False, True, True, False, True, True, False, True, True, True, True, True, False, True, True, True, True, True, False, True, True, False, True, True, True, True, True, True, True, False, True, True, True]\n",
      "Features: \n",
      " \tinput_ids: [101, 100, 100, 1010, 100, 100, 1010, 100, 7570, 2100, 1037, 100, 4895, 20228, 10936, 2080, 2139, 4937, 2953, 3401, 2033, 8583, 1012, 16371, 18697, 100, 1012, 2112, 4313, 3972, 9986, 2063, 2139, 4372, 10624, 2139, 2456, 1010, 2474, 10768, 7507, 2139, 100, 2139, 2474, 2741, 27742, 18499, 2112, 2063, 2139, 2474, 100, 1010, 11498, 3449, 11503, 26282, 2139, 100, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tinitial_mask: [0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tner_label_ids: [1, 2, 2, 2, 5, 6, 2, 2, 2, 1, 2, 7, 2, 2, 1, 1, 2, 2, 1, 1, 2, 1, 1, 2, 1, 2, 1, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 7, 2, 2, 2, 2, 1, 2, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "_____________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing Dataset data/finetuning_data/chunk/test.txt: 100%|██████████| 1517/1517 [00:01<00:00, 779.19 Dicts/s]\n",
      "09/03/2020 17:35:33 - INFO - farm.data_handler.data_silo -   Examples in train: 8323\n",
      "09/03/2020 17:35:33 - INFO - farm.data_handler.data_silo -   Examples in dev  : 1915\n",
      "09/03/2020 17:35:33 - INFO - farm.data_handler.data_silo -   Examples in test : 1517\n",
      "09/03/2020 17:35:33 - INFO - farm.data_handler.data_silo -   \n",
      "09/03/2020 17:35:33 - INFO - farm.data_handler.data_silo -   Longest sequence length observed after clipping:     128\n",
      "09/03/2020 17:35:33 - INFO - farm.data_handler.data_silo -   Average sequence length after clipping: 48.31575153189956\n",
      "09/03/2020 17:35:33 - INFO - farm.data_handler.data_silo -   Proportion clipped:      0.005046257359125316\n",
      "09/03/2020 17:35:37 - INFO - filelock -   Lock 5702682888 acquired on /Users/subir/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157.lock\n",
      "09/03/2020 17:35:37 - INFO - transformers.file_utils -   https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /Users/subir/.cache/torch/transformers/tmpx3aavbmj\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf6d9922053f4cf380e1ea8f4f917156",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09/03/2020 17:38:11 - INFO - transformers.file_utils -   storing https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin in cache at /Users/subir/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "09/03/2020 17:38:11 - INFO - transformers.file_utils -   creating metadata file for /Users/subir/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "09/03/2020 17:38:11 - INFO - filelock -   Lock 5702682888 released on /Users/subir/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157.lock\n",
      "09/03/2020 17:38:11 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /Users/subir/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09/03/2020 17:38:13 - INFO - transformers.modeling_utils -   All model checkpoint weights were used when initializing BertModel.\n",
      "\n",
      "09/03/2020 17:38:13 - INFO - transformers.modeling_utils -   All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "09/03/2020 17:38:13 - WARNING - farm.modeling.language_model -   Could not automatically detect from language model name what language it is. \n",
      "\t We guess it's an *ENGLISH* model ... \n",
      "\t If not: Init the language model by supplying the 'language' param.\n",
      "09/03/2020 17:38:13 - INFO - farm.modeling.prediction_head -   Prediction head initialized with size [768, 13]\n",
      "09/03/2020 17:38:27 - INFO - farm.modeling.optimization -   Loading optimizer `TransformersAdamW`: '{'correct_bias': False, 'weight_decay': 0.01, 'lr': 1e-05}'\n",
      "09/03/2020 17:38:29 - INFO - farm.modeling.optimization -   Using scheduler 'get_linear_schedule_with_warmup'\n",
      "09/03/2020 17:38:29 - INFO - farm.modeling.optimization -   Loading schedule `get_linear_schedule_with_warmup`: '{'num_warmup_steps': 104.4, 'num_training_steps': 1044}'\n",
      "09/03/2020 17:38:34 - INFO - farm.train -   \n",
      " \n",
      "\n",
      "          &&& &&  & &&             _____                   _             \n",
      "      && &\\/&\\|& ()|/ @, &&       / ____|                 (_)            \n",
      "      &\\/(/&/&||/& /_/)_&/_&     | |  __ _ __ _____      ___ _ __   __ _ \n",
      "   &() &\\/&|()|/&\\/ '%\" & ()     | | |_ | '__/ _ \\ \\ /\\ / / | '_ \\ / _` |\n",
      "  &_\\_&&_\\ |& |&&/&__%_/_& &&    | |__| | | | (_) \\ V  V /| | | | | (_| |\n",
      "&&   && & &| &| /& & % ()& /&&    \\_____|_|  \\___/ \\_/\\_/ |_|_| |_|\\__, |\n",
      " ()&_---()&\\&\\|&&-&&--%---()~                                       __/ |\n",
      "     &&     \\|||                                                   |___/\n",
      "             |||\n",
      "             |||\n",
      "             |||\n",
      "       , -=-~  .-^- _\n",
      "              `\n",
      "\n",
      "Train epoch 0/3 (Cur. train loss: 2.6822):   2%|▏         | 4/261 [01:48<1:56:23, 27.17s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-9ae79c90242e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0mner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-9ae79c90242e>\u001b[0m in \u001b[0;36mner\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# 7. Let it grow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;31m# 8. Hooray! You have a model. Store it:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/Electra-PszQOton/lib/python3.7/site-packages/farm/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    288\u001b[0m                 \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m                 \u001b[0mper_sample_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits_to_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward_propagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mper_sample_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0;31m# Perform  evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/Electra-PszQOton/lib/python3.7/site-packages/farm/train.py\u001b[0m in \u001b[0;36mbackward_propagate\u001b[0;34m(self, loss, step)\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_acc_steps\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/Electra-PszQOton/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/Electra-PszQOton/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "    model = AdaptiveModel(\n",
    "        language_model=language_model,\n",
    "        prediction_heads=[prediction_head],\n",
    "        embeds_dropout_prob=0.1,\n",
    "        lm_output_types=[\"per_token\"],\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    # 5. Create an optimizer\n",
    "    model, optimizer, lr_schedule = initialize_optimizer(\n",
    "        model=model,\n",
    "        learning_rate=1e-5,\n",
    "        n_batches=len(data_silo.loaders[\"train\"]),\n",
    "        n_epochs=n_epochs,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    # 6. Feed everything to the Trainer, which keeps care of growing our model into powerful plant and evaluates it from time to time\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        data_silo=data_silo,\n",
    "        epochs=n_epochs,\n",
    "        n_gpu=n_gpu,\n",
    "        lr_schedule=lr_schedule,\n",
    "        evaluate_every=evaluate_every,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    # 7. Let it grow\n",
    "    trainer.train()\n",
    "\n",
    "    # 8. Hooray! You have a model. Store it:\n",
    "    save_dir = \"saved_models/bert-german-ner-tutorial\"\n",
    "    model.save(save_dir)\n",
    "    processor.save(save_dir)\n",
    "\n",
    "\n",
    "    # 9. Load it & harvest your fruits (Inference)\n",
    "    basic_texts = [\n",
    "        {\"text\": \"Where do Mr smith want to go for lunch?\"},\n",
    "        {\"text\": \"Martin muller is a poet from  Berlin\"},\n",
    "    ]\n",
    "    model = Inferencer.load(save_dir)\n",
    "    result = model.inference_from_dicts(dicts=basic_texts)\n",
    "    print(result)\n",
    "\n",
    "    model.close_multiprocessing_pool()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
